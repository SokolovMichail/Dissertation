\documentclass[14pt]{mmcs_article}
\usepackage[russian]{babel}
\usepackage{amsmath, amsthm, amsfonts, amssymb}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage[linesnumbered,boxed]{algorithm2e}


\newenvironment{myenumerate}
{ \begin{enumerate}
		\setlength{\itemsep}{0pt}
		\setlength{\parskip}{0pt}
		\setlength{\parsep}{0pt}     }
	{ \end{enumerate}                  } 

%\graphicspath{{images/}}%путь к рисункам

\begin{document}

% Титульные листы
% раскомментировать требуемое
%\include{Titul3k} % для курсовой
%\include{TitulBak}% для работы бакалавра
\include{TitulMag}% для работы магистра

\renewcommand{\contentsname}{Оглавление}

\tableofcontents

%=======================
\newpage
\addcontentsline{toc}{section}{Постановка задачи}

\section*{Постановка задачи}


Цель работы - создание мета-рекомендательной системы, способной адаптироваться и давать рекомендации для любого интернет-магазина. Для достижения цели был сформирован набор рабочих задач:
\begin{enumerate}
	\item Анализ полученных из интернет-магазинов треков активности пользователей и описания продаваемых товаров
	\item Выбор методов рекомендации, подбор типов моделей-рекомендаторов.
	\item Формирование представлений данных для создания и обучения моделей.
	\item Обучение моделей и поиск оптимальных гиперпараметров.
	\item Добавление возможности автоматического пересоздания представлений данных и моделей и переобучения моделей в связи с изменившимися данными и возможности использования оперативной истории без переобучения моделей
	\item Интеграция в существующую платформу интернет-магазинов.
\end{enumerate}

Для решения задачи( по согласованию с заказчиком) был выбран ЯП Python с пакетами numpy v 1.19.5, scikit-learn v 1.0.0, scipy v 1.7.1, implicit v 0.4.4, pandas v 1.3.5 и TensorFlow v 2.4.2, а также использовался NVidia CUDA Toolkit v 10.1 для ускорения обучения определенных нейросетевых моделей с использованием GPU.

В дальнейшем может быть апдейтнем версию TensorFlow до 2.7.*... Но пока нет. 


%=======================
\newpage
\addcontentsline{toc}{section}{Введение}
\section*{Введение}

Дальнейшее повышение эффективности работы субьектов электронной коммерции, на наш взгляд, связано с расширением списков клиентов, получающих доступ к упомянутым субьектам, а также с персонализацией онлайн-маркетинга. По оценкам McKinsey \cite{INTRO:a1}, 35\% выручки Amazon или 75\% Netflix приходится именно на рекомендованные товары и процент этот, вероятно, будет расти. В данном отчете описана попытка создания решения на базе собранной информации интернет-магазинов. 

Задача рекомендательной системы – проинформировать пользователя о товаре, который ему может быть наиболее интересен в данный момент времени. Клиент получает информацию, а сервис зарабатывает на предоставлении качественных услуг. Услуги — это не обязательно прямые продажи предлагаемого товара. Сервис также может зарабатывать на комиссионных или просто увеличивать лояльность пользователей, которая потом выливается в рекламные и иные доходы.

В зависимости от модели бизнеса рекомендации могут быть его основой, как, например, у компании TripAdvisor, а могут быть просто удобным дополнительным сервисом (как, например, в каком-нибудь интернет-магазине одежды), призванным улучшить Customer Experience и сделать навигацию по каталогу более удобной. В данной работе рекомендательная система используется как дополнительный сервис в дополнение к основному сервису(интернет-магазин), в качестве предмета рекомендаций используются товары магазина. 

Эта работа может быть использована в предприятиях электронной коммерции (интернет-магазинах) для быстрого и легкого создания и обновления автоматической рекомендательной системы и соответственно, имеет высокую практическую значимость.
Результаты данной работы апробированы на конференции "Математика. Компьютер. Образование. 2022".

%=======================
\newpage


\section{Входные данные. EDA}\label{dsfs}
Заказчиком были предоставлены экземпляры файлов, выгружаемых с с интернет-магазинов. 
Файл 1 типа - .csv  файл, содержащий описание событий происходящих в интернет-магазине, в дальнейшем - данные о событиях. \\
Всего файл 1 типа содержит 44 типа полей, однако некоторые из них не заполнены во всем датасете. Далее следует список полей и гипотез для каждого поля. Незаполненные поля, а также поля не несущие полезной информации(сервисные хеши и т.д) опущены.
\begin{myenumerate}
	\item datetime. Поле времени начала события. 
	\item userip. Поле, в котором указывается IPv4-адрес, с которого осуществлялся доступ. Гипотеза: можно использовать для генерации рекомендаций по стране пользователя.
	\item userid. Цифробуквенный уникальный ID пользователя в системе, основной способ идентификации пользователя.
	\item useragent. Фрагмент HTML-header, указывающий на используемый браузер. Гипотеза: можно использовать тип браузера для дифференциации положения владельца в обществе. Нельзя. TODO
	\item eventtype. Тип произошедшего события. 
	\begin{myenumerate}
		\item ProductView - события просмотра товара пользователем. 
		\item AddToCart - события добавления пользователем товара в корзину. 
		\item FacetSelection - событие выбора пользователем фильтра показа товаров.  
		\item Search - событие поиска пользователем товара по названию.
		\item AutoComplete - событие автодополнения запроса пользователя. 
		\item ClickOnSearchResult - событие нажатия на результат поисковой выдачи. 
	\end{myenumerate}
	\item usersearchphrase Запрос пользователя. Используется в типах событий AutoComplete, Search. Гипотеза: Может быть использовано для лингвистического анализа запроса.
	\item correctedsearchphrase. Исправленный запрос пользователя. Используется в типе событий Search. 
	\item facetname. Имя фильтра по которому производился поиск. Используется в типе событий Facet Selection. 
	\item facetvalue. Значение фильтра. Используется в типе событий Facet Selection. Гипотеза: может быть использовано при рекомендации, отфильтровывая рекомендации по соответствующему значению. 
	\item productid. Внутренний уникальный ID продукта. 
\end{myenumerate}

Файл 2 типа - .json файл содержащий описания товаров, а также фильтров товаров, представленных в магазине. Вследствие предполагаемой универсальности системы, а также большого количества полей, являющимися пустыми, приведем описание только используемых универсальных полей, и обобщенное описание остальных полей.\\
В данном файле интерес представляют два поля: Items и Facets. Рассмотрим их подробнее. \\
Поле Items:
\begin{myenumerate}
	
	\item CatalogID. Уникальный числовой ID продукта. Совпадает со значением поля productid в событиях типа ProductView.
	\item Name. Имя товара. Гипотеза: может быть использовано для поиска похожих по названию товаров.
 	\item OrdersCount. Количество заказанных товаров. Гипотеза: можно использовать для фильтрации товаров по популярности.
	\item Типы и значения фильтров, отвечающих товару.
\end{myenumerate}

Поле Facets:
\begin{myenumerate}
	
	\item FacetName. Имя фильтра.
	\item TotalHits. Количество раз, который этот фильтр был выбран. Гипотеза: Может быть использовано для определения самых часто выбираемых фильтров.
	\item Values. Список возможных значений, которые может принимать фильтр. Может иметь как категориальный тип, так и числовой тип. 
\end{myenumerate}

Особо следует отметить, что эти стандартизированные выгрузки данных не содержат в себе ни информации об оценках пользователями купленных товаров, ни информации о покупках пользователя, то есть в наличии только implicit feedback. Подробнее рассмотрим отличия explicit и implicit feedback.

% вставить ссылку на одну из ALS статей Collaborative Filtering for Implicit Feedback Datasets
\subsection{Explicit Feedback и Implicit Feedback}
Рекомендательные системы используют два основных типа обратной связи от пользователей. Это explicit feedback(явная обратная связь) и implicit feedback(неявная обратная связь). Приведем примеры каждой из обратных связей.

Явная обратная связь - это оценки контента пользователями. Такими оценками могут быть, например, количество звезд, числовые оценки по некоторым шкалам, и даже простое нравится/не нравится, использующееся, допустим, видеохостингом YouTube.

Неявная обратная связь - это любые записанные действия пользователя при взаимодействии с контентом. Просмотры товаров, история покупок, добавление товара в корзину, покупка товара - все это является одним из вариантов implicit feedback. 

Эти два типа связей значительно отличаются друг от друга по большому количеству пунктов.
\begin{myenumerate}
	\item Количество данных обратной связи. Для явной обратной связи количество собранных данных всегда значительно меньше, чем количество данных для неявной обратной связи. Кроме того, не всегда в системах вообще существуют встроенные механизмы  сбора данных явной обратной связи и/или возможность их создания. 
	\item Негативные оценки. При явной обратной связи всегда существует явная негативная обратная связь(или возможность ее установления). Так, допустим, недовольный товаром человек может поставить в оценке одну звезду из пяти возможных. При неявной обратной связи же практически невозможно установить негативный feedback, любая такая связь сама по себе будет позитивной. Так, допустим, отсутствие записанного взаимодействия пользователя и конкретной части контента может быть как в силу негативного отношения пользователя к данной части контента, так и в силу отсутствия взаимодействия этих пользователей вообще.  
	\item Наличие шума в данных. Когда мы проводим сбор implicit feedback, невозможно достоверно установить их предпочтения и истинные мотивы совершаемых ими действий. Так, например, данные о покупке(или просмотре/добавлении в корзину) пользователем продукта далеко не всегда являются следствием хорошего отношения пользователя к продукту. Существует вероятность что продукт был приобретен в качестве подарка, или что пользователь был разочарован при использовании продукта.
	\item Отличие значения данных. Так, при явной обратной связи числовое значение(количество покупок, оценка качества) означает предпочтение одному продукту другого, в то время как при неявной обратной связи это означает лишь частоту взаимодействия. Тем не менее, хотя более высокая частота взаимодействия не всегда отражает предпочтение одного продукта другому, повторяющееся действие с более высокой вероятностью показывает предпочтения пользователя.
	\item Учет дополнительных признаков. Так, при неявной обратной связи необходимо учитывать также доступность каждого конкретного продукта в момент времени, повторяемые покупки и т.д. При явной обратной связи такое не требуется.
\end{myenumerate}
По причинам, которые будут озвучены ниже, в работе используется только implicit feedback.

После проведенного EDA, было принято решения использовать лишь следующие поля:

Из файлов 1 типа(событий):

\begin{myenumerate}
		\item datetime.
		\item userid. 
		\item productid.
		\item eventtype. Было принято решение для простоты использовать исключительно типы событий ProductView и AddToCart, так как они несут наибольшее количество полезной информации для рекомендательной системы. 
\end{myenumerate}

Из файлов 2 типа(предметов):

\begin{myenumerate}
	\item CatalogID.
	\item Типы и значения фильтров, отвечающих товару
\end{myenumerate}

Кроме того, такой подход позволяет значительно сократить количество используемой ОЗУ и памяти для хранения данных.

Для обработки данных был создан специализированный пайплайн. Он состоит из 6 стадий обработки данных, которые можно представить в виде следующего графа.

\begin{figure}[H]
\begin{tikzpicture}[main/.style = {draw, rectangle},node distance= 1cm,align=left] 
\node[main] (1) {prepare\_actions(1)}; 
\node[main] (2) [below=0.5cm of 1] {prepare\_df\_splits(2)};
\node[main] (3) [below left=0.5cm and -1cm of 2] {prepare\_csr\_splits(3)}; 
\node[main] (4) [below right=0.5cm and -2cm of 2] {prepare\_items\_by\_users(4)}; 
\node[main] (5) [right=1cm of 1] {prepare\_item\_profiles(5)}; 
\node[main] (6) [below right=0.5cm and -2cm of 4] {prepare\_user\_profiles(6)}; 
\draw[->] (1) -- (2);
\draw[->] (2) -- (3);
\draw[->] (2) -- (4);
\draw[->] (4) -- (6);
\draw[->] (5) -- (6);
\end{tikzpicture}
\caption{Граф пайплайна системы}\label{stud:fig:2}
\end{figure}
На каждом этапе формируется одно из представлений данных. Кратко опишем их.

\begin{myenumerate}
	\item Стадия prepare\_actions. На ней формируется временное представление - $pandas$.$dataframe$, содержаший в себе записи о всех событиях типа  ProductView и AddToCart.
	\item Стадия prepare\_df\_splits. На ней формируется основное представление данных, представляющее собой два  $pandas$.$dataframe$ - соответственно train и test. train содержит в себе все события, произошедшие до определенной даты включительно, test - все события, которые произошли после определенной даты. Важно, что test содержит в себе события только тех пользователей, которые входят во множество train. 
	\item Стадия prepare\_csr\_splits. На ней, на основе результатов стадии \\ prepare\_df\_splits формируются два основных представления данных CSR(csr\_train и csr\_test) - разреженные матрицы формата \\$scipy$.$sparse$.$csr\_matrix$, размерностью $M \times N$, где $M$ - количество пользователей в системе, а $N$ - количество продуктов в системе. Данные матрицы содержат все взаимодействия пользователей со всеми товарами(c повышающими коэффициентами для событий AddToCart). Так, одно событие AddToCart рассматривается как одно или более событий ProductView - конкретный коэффициент задается в конфигурационном файле системы. Путем экспериментов, был подобран коэффициент равный 10.
	\item Стадия prepare\_items\_by\_users. На этой стадии создается словарь взаимодействия userid и productid, что используется для контроля обучения моделей и в стадии prepare\_user\_profiles.
	\item Стадия prepare\_item\_profiles. На этой стадии формируется представление данных ItemProfileStorage - создается таблица(pandas.DataFrame), содержащая профили всех товаров, построенная на извлеченных из .json файла фильтров показа и их значений. Строки таблицы - товары, столбцы - характеристики товаров. В основном количестве признаки являются категориальными, но, в процессе подготовки представления данных, преобразуются в бинарные.
	\item Стадия prepare\_user\_profiles. На этой стадии формируется представление данных UserProfileStorage - таблица(pandas.DataFrame), содержащая профили всех пользователей, построенная на извлеченных из .json файла фильтров показа и их значений и представлении данных IP. Каждый профиль пользователя представляет собой алгебраическую сумму профилей всех товаров, с которыми он взаимодействовал(точно так же, как в CSR - c повышающими коэффициентами для событий AddToCart). Это основа для собственного подхода, объединяющего принципы Content based подхода и коллаборативной фильтрации.
	
\end{myenumerate}

Основные представления данных, которые будут использованы в дальнейшем - CSR, ItemProfileStorage, UserProfileStorage.


%=======================

\section{Теоретическая часть}\label{dsfs}
\subsection{Исследование трудов по теме}
Как уже говорилось выше, поставленная задача - создание максимально универсальной рекомендательной системы, подходящей для любого интернет-магазина при условии стандартизированной выгрузки данных.
Предварительно стоит отметить, что есть две категории товаров:
\begin{itemize}
	\item Повторяемые товары. Это те товары-расходники, которые люди покупают часто. К таким относятся, например, продукты питания, бритвенные станки, предметы бытовой химии.
	\item  Неповторяемые товары. Это такие товары, которые редко приобретают повторно. Примеры таких товаров - электроника, бытовая техника, ювелирные украшения.
\end{itemize}
Давайте опишем нашу рекомендательную систему:
\begin{enumerate}
\item Предмет рекомендации. Для данного проекта предметом рекомендации может являться только товар. Ситуация с применением системы для магазинов, использующих услуги не рассматривалась. В силу предполагаемой максимальной универсальности системы, она предполагает одинаковое отношение как к товарам из повторяемой группы, так и к товарам из неповторяемой группы.
\item Цель рекомендации. Здесь цель рекомендации - информирование пользователя о товарах, которые могут ему подойти, и в конечном счете - покупка пользователем дополнительных товаров.
\item Контекст рекомендации. На момент получения рекомендации предполагается, что пользователь смотрит товары и/или находится в корзине.
\item Иcточники рекомендации. Здесь это как общая аудитория магазина, так и схожие по интересам пользователи, в зависимости от подхода.
\item Степень персонализации рекомендации. Здесь в зависимости от подхода используются разные степени персонализации.
\item Алгоритм рекомендации. Об этом будет написано ниже. 
\end{enumerate}

Путем исследования, было установлено, что существует три основных подхода к созданию моделей для решения следующих задач - Summary-based модели, Content-based модели и Collaborative filtering модели. В подходе collaborative filtering также выделяют отдельный субподход - matrix factorization.  Опишем отличительные особенности этих подходов. 

Подход Summary-based. Данный подход является наиболее простым - и, тем не менее, достаточно эффективным. Он основан на неперсонализированной оценке популярности каждого товара, и соответственно, рекомендации пользователю самых популярных товаров.

Подход Collaborative Filtering. Данный класс систем начал активно развиваться в 90-е годы. В рамках подхода рекомендации генерируются на основании интересов других похожих пользователей, таким образом являясь результатом «коллаборации» множества пользователей. Отсюда и  происходит название метода. Этот метод уже является персонализированным - т.е. рекомендации подбираются персонально под каждого пользователя.

Одними из главных субподходов для collaborative filtering является подходы на основе факторизации матриц - так называемые "matrix factorization". В основе такого субподхода лежит матрица товар-клиент - разреженная матрица взаимодействия оценок товаров и пользователей. Каждое значение суть мера заинтересованности пользователя в товаре. 

Подход  Content-based. Данный подход основан на описании товара. Для товаров создаются признаковые описания, представляющие собой векторы категориальных признаков.
В рамках подхода рекомендуются товары, которые наиболее похожи на популярные у пользователя продукты.

\subsection{Проблема холодного старта}
Проблема холодного старта - одна из типичных ситуаций для рекомендательной системы. Заключается она в том, что в момент добавления нового пользователя и товара о нем практически ничего не известно. В силу универсальности создаваемой системы, принято решение данную проблему игнорировать. Так, предположительно, система будет пересоздаваться и переобучаться каждые 168 часов, что должно нивелировать отсутствие механизмов смягчения проблемы холодного старта. Кроме того, модели item-based не подвержены этой проблеме.

\subsection{Метрики оценки моделей}
Введём общие обозначения для метрик:
$N$ - количество пользователей.
$K$ - количество товаров. 
$rel(i)$ - является ли товар на позиции $i$ релевантным.

Оценка моделей производилась по набору следующих метрик:
\begin{enumerate}
	\item Метрика NAP@K(Normalized Average Precision at K) является одной из типичных метрик для измерения качества рекомендательной системы. Метрика сравнивает N рекомендаций системы и N наиболее релевантных товаров для пользователя, учитывая их позицию. 
	\begin{equation}
		NAP@K = \frac{1}{N} \sum_{j=1}^{N} \frac{1}{K}\sum_{i=1}^{K}rel(i)
	\end{equation}
	\item Метрика NDCG@K(Normalized Distributed Continued Gain at K) также применяется достаточно часто. Она является модификацией Cumulative Gain at K c учетом порядка элементов.
	\begin{equation}
		nDCG@K= \frac{1}{N} \ sum{j=1}^N \sum{i=1}{K} \frac{2^{rel(i)} }{log_2(k+1)} 	
    \end{equation}   
	\item Метрика IOR@K(Intersection Over Recommended at K). Данная метрика предлагается как аналог NAP, с учетом того что порядок представления рекомендаций не имеет значения. Действительно, для пользователя нет особой важности в том, в каком порядке ему представляются рекомендации.
	\begin{equation}
		IOU@K \frac{1}{N} \sum_{j=1}^N  /frac{(\sum_{i=1}^{K} rel(i))}{K} 
	\end{equation} 
	\item Метрика HappyUsersRatio@K. Данная метрика была предложена заказчиком как методика измерения эффективности системы. Идея данной метрики заключается в том, что для каждого пользователя если множества рекомендаций нашей модели и множество actuals имеют хотя бы одно пересечение, то считается, что наша рекомендация удачна. Она имеет интересное практическое значение - здесь K - количество рекомендаций, которые интернет-магазин может поместить в ленту.
	\begin{equation}
	   HappyUsersRatio@K = \frac{1}{N}\sum_{j=1}^{N} max(1,\sum_{i=1}^{K} rel(i)) 		
	\end{equation}
\end{enumerate}

\section{Модели}

\subsection{Общее описание моделей}
Далее были созданы одна модель - baseline и 6 моделей машинного обучения. Перечислим их по порядку: TopN, ALS, BPR, AE, IP, UIP, DRN. Выход каждой модели - список товаров, которые необходимо рекомендовать пользователю. \\
Стоит заметить, что процесс генерации и обучения моделей также является полностью автоматизированным, что позволяет переобучать модели без участия ml-инженеров. К сожалению, все модели(за исключением Top30) жестко привязываются к данным, что делает процесс дообучения на новых данных невозможным, вследствие чего используется процесс полного переобучения.


\subsection{TopN}
Модель TopN является одной из наиболее частых и простых в как в составлении, так и в использовании моделей и является представителем Summary-based подхода. Путем парсинга представления данных CSR производится сортировка товаров по количеству взаимодействий, и любому пользователю предлагается N самых популярных товаров, где N задается необходимостями системы. Данная модель используется в качестве baseline для всех остальных моделей, а также для дополнения списка рекомендаций в случае если другие модели не смогли дать необходимое их число.
\subsection{ALS}
Модель ALS \cite{ALSA1} - одна из классических моделей рекомендательных систем. Данная модель принадлежит к классу collaborative filtering. \\
Введем отношения, необходимые для работы данной модели.
% Поменять потом m и n местами.
Примем общее количество пользователей на данный момент времени в системе как $n$, общее количество товаров на данный момент времени в системе как $m$.Запишем все взаимодействия пользователей и продуктов в матрицу $R_{n \times m}$, где $r_{u,i}$ - количество раз которое пользователь $u$ взаимодействовал(в нашем случае просматривал или клал в корзину) товар $i$.  Результирующая матрица является разреженной, так как на практике практически невозможна ситуация когда каждый пользователь взаимодействует с каждым товаром, что отражается нулевыми значениями в матрице. Кроме того, как предлагает статья \cite {ALS:rwe}, введем $\mathrm{T}$ - множество $(u, i)$ :$r_{u,i} > 0$ и $\hat{r}_{ui}$ - предсказанное взаимодействие пользователя с системой.

Процесс факторизации матрицы позволяет представить матрицу $R$ как $R \approx P Q^T$, где $P \in  \mathbb {R}^{n\times k}$ - матрица признаков пользователя, а  $Q \in  \mathbb {R}^{m\times k}$, где $k$ - заранее определенная константа. 
Соответственно $p_u \in \mathbb {R}^{k}$ это строка $u$ в матрице $P$, а $q_i \in \mathbb {R}^{k}$ это строка $i$ в матрице $Q$. 

Формула для предсказания  $\hat{r}_{ui}$:
\begin{equation}
	 \hat{r}_{ui} = p_u^T q_i
\end{equation}

Статья \cite{ALS:CFIFD} предлагает ввести переменные $s_{ui}$, которые можно принять как меру предпочтения пользователя $u$ товару $i$. Для удобства использования, бинаризуем их. Тогда
\begin{equation}
	s_{ui} = \begin{cases}
		1 & r_{ui} > 0 \\
		0 & r_{ui} = 0
	\end{cases}
\end{equation}

Тем не менее, сразу использовать эти значения $s_{ui}$ нерационально. Статья \cite{ALS:CFIFD} предлагает введение дополнительных переменных $c_{ui}$ таких, что $c_{ui} = 1 + \alpha * r_{ui}$. Эти переменные отвечают за меру нашей уверенности в значении $y_{ui}$ Тогда всегда будет существовать ненулевое предпочтение пользователя $u$ товару $i$, и при этом чем больше количество взаимодействий пользователя и товара зафиксировано, тем более высокое значение примет $c_{ui}$. $\alpha$ здесь - повышающий коэффициент, который предлагается принять равным 40. 

%TODO Добавить кусочек про модель без оптимизации.

Введем ценовую функцию:
\begin{equation}
	g(P, Q) = \sum_{u, i \in \mathrm{T}} (c_{ui}(\hat{r}_{ui} - r_{ui}^2) + \lambda_P\parallel p_u \parallel + \lambda_Q\parallel^2 q_i \parallel^2) 
\end{equation}

В силу того что будет использоваться метод оптимизации путем использования метода сопряженных градиентов, значения $c_{ui}$ и $r_{ui}$ не будут константными в позициях $(u,i) \not\in \mathbb{T}$. Обозначим такие исходные значения как $c_0$, $r_0$.

Особенность примененной здесь модели заключается в том, что для ускорения процесса вычислений применяется взвешенная гребневая регрессия, которую можно обозначить как WRR(Weighted Ridge Regression).

Приведем один из алгоритмов, часто применяющихся для приближенного расчета WRR-метода сопряженных градиентов.

\begin{algorithm}[H]\label{al:1}
	\caption{Предусловленный метод решения системы $Aw = b$ методом сопряженных градиентов.}
	\KwIn{$A, M \in \mathbb{R}^{d \times d}, b, w_0 \in \mathbb{R}^{d \times 1}, E \in \mathbb{N}$}
	\KwOut{$w_0 \in \mathbb{R}^{d}$}
	
	$w \leftarrow w_0, r \leftarrow b - Aw, z \leftarrow M^{-1}r, p \leftarrow z$
	\For{$k \leftarrow 1...E$}\do{
		\eIf{$\parallel r \parallel < \epsilon$}{return $w$}
		{$\gamma$ $\leftarrow$ $r^Tz$
		 $\alpha \leftarrow \gamma / (p^TAp)$
		 $x \leftarrow x + \alpha r$
		 $r \leftarrow r - \alpha Ap$
		 $z \leftarrow M^{-1} r$
		 $\beta \leftarrow \gamma / (r^TAz)$
		 $p \leftarrow z + \beta p$
	 	}
	}
\end{algorithm}

Здесь $\epsilon$ - необходимая точность.

Расчет $(u,i)$ происходит по следующей формуле: $\hat{r}_{ui} = p_u^T q_i$,  $p_u = s_u \sum_{j \in \mathbb{J}}w_j$, $s_u = (n_u + 1)^{\frac{1}{2}}$. При этом, ценовая функция остается такой же, с тем отличием, что $P$ может быть выражена через $W$ и обучающее множество. Функция все также является невыпуклой, поэтому используется не точная, но примерная минимизация по методу IALS.

Пусть $W \in \mathbb{R}^{m \times k}$ -матрица векторов $w_j$.  Введем $B \in R^{n \times m}$ такую, что $B_{ui} = r_{ui}s_u$. Исходя из этого, верно следующее выражение: $P = BW$, где $B$ - это разреженная матрица. 

Во время оптимизации используется три комплекта параметров - $P, Q, W$. Алгоритм следующий:
Для $e = 1 ... I$:
\begin{enumerate}
	\item $Q-step$: For $i \in \mathbb{I}: q_i \leftarrow WRR(P, \bar{r}_i, \bar{c}_i,n_i\lambda_QI)$
	\item $P-step$: For $u \in \mathbb{U}: p_u \leftarrow WRR(Q, r_u, c_u,n_u\lambda_PI)$
	\item $W-step$: For $k \in \mathbb{K}: q_i \leftarrow WRR(B, \bar{p}_k, 1 ,\lambda_WI)$
	\item For $u \in \mathbb{U}: p_u \leftarrow p_u = s_u\sum_{j \in \mathbb{I_u}} w_j$
\end{enumerate},
где WRR - алгоритм \ref{al:1}.

Рассмотрим шаги алгоритма подробнее.
Первый шаг оптимизирует $Q$ в уравнении $R \approx PQ^T$. Здесь $\bar r_i \in \mathbb{R}^{N \times 1}$  и  $r_u \in \mathbb{R}^{M \times 1}$ - столбец $i$ и ряд $u$ матрицы $R$. Векторы $ \bar{с_i} \in \mathbb{R}^{N \times 1}$ и $\bar{с_u} \in \mathbb{R}^{M \times 1}$ соответственно составлены из значений $c_ui$. В качестве WRR может быть использован любой алгоритм расчета взвешенной гребневой регрессии, причем $\bar r_i$, $\bar c_i$ не имеют необходимости полно пересчета каждый раз, вследствие того, что изменяется лишь малая их часть. 
Второй шаг очень похож на первый, но оптимизирует лишь $P$. Третий шаг отличен в том, что он оптимизирует только $W$ из $P \approx BW$, причем он направлен на лучшую аппроксимацию матрицы $P$, а не $R$. Здесь  $\bar p_k \in \mathbb{R}^{N \times 1}$ - это $k$-й столбец матрицы $P$, веса взвешенной гребневой регрессии константно равны 1.

Описанный алгоритм реализован в библиотеке implicit v.0.4.4, которая используется в данном проекте. Используется представление данных CSR.


\subsection{BPR}
Модель BPR также принадлежит к классу collaborative filtering. \\

Обозначим множество всех пользователей как $U$, множество всех товаров как $I$. Доступные данные по Implicit feedback -  $S = U \times I$. Введем функции предпочтения пользователя: $ >_u \in I^2$, которая отвечает следующим условиям:
\begin{itemize}
	\item $\forall i, j : i \neq j \rightarrow i >_u j \vee j >_u i$
	\item $\forall i, j : i >_u j \wedge j >_u i \rightarrow i = j$
	\item $\forall i, j, k :  i >_u j \wedge j >_u k  \rightarrow i >_u k $
\end{itemize}
Также, статья \cite{BPR:1205.2618} предлагает ввести следующие обозначения. 
\begin{itemize}
	\item $I_u+: \{i \in I \wedge (u,i) \in S\}$
	\item $U_i+: \{u \in U \wedge (u,i) \in S\}$
\end{itemize}

Как уже говорилось, зачастую данные Implicit Feedback крайне разреженные. Кроме того, в Implicit Feedback присутствует только положительная обратная связь - остальные данные не заполнены. Стоит отметить, что implicit feedback - незаполненные данные на самом деле являются смесью отрицательных данных и незаполненных.
Обычно такие данные просто отбрасываются, но в нашем случае они будут использованы.

Типичный подход для рекомендательных систем - расчет такого значения $x_{ui}$ которое отражает степень предпочтения пользователя к данному товару. Тренировочным данным $(u,i) \in S$ присваивается позитивная метка, а любым другим комбинациям $(u,i) \notin S$ - негативная. Это означает, что модель натренирована предсказывать 1 для предметов принадлежащих $S$, и 0 в ином случае. Однако, в данном подходе есть проблема - все элементы которые модель должна ранжировать в дальнейшем имеют представлены модели как негативная обратная связь. Соответственно, достаточно чувствительная модель будет иметь плохую эффективность - ведь она будет предсказывать только 0.    

Соответственно, здесь используется другой подход - используя в качестве тренировочного множества пары товаров, причем оптимизация происходит в зависимости от корректности ранжирования пары, в отличие от использования одиночных "верных" товаров. То есть задача - насколько это возможно, получить из $S$ отношения $>_u$ для каждого пользователя. Так, если $ (u,i) \in S $ - то можно считать что пользователь $ u $ предпочитает $ i $. Формализуем: создадим тренировочный датасет $ D_S: U \times I \times I $ такой, что:
\begin{equation}
	D_S := \{ (u,i,j) | i \in I_u+ \wedge j \in I \\I_u+ \}
\end{equation}
То есть мы создаем пары товаров для пользователей такие, что пользователь $ u $ предпочитает товар $ i $ товару $ j $.
Данный подход предполагает два преимущества:
\begin{itemize}
	\item Датасет $D$ состоит из позитивных и негативных пар и незаполненных значений. Незаполненные значения между двумя товарами с которыми не взаимодействовал пользователь - это как те значения, которые требуется предсказать. Соответственно, если рассмотреть попарно, то тренировочный и тестовый датасеты разделены.
	\item При этом тренировочные данные являются подмножеством $D$. 
\end{itemize}     

Рассмотрим алгоритм работы BPR.
Формулировка Байесовской задачи для нахождения персонализированного ранжирования для товара $  i \in I$ заключается в максимизации следующей условной вероятности:
\begin{equation}
	p(\theta | >_u) \propto p(>_u | \theta)p(\theta).
\end{equation} 
Здесь $\theta$ - вектор параметров модели, а $ >_U $ - это действительные предпочтения пользователя $ u $, причем предполагается, что все пользователи действуют независимо друг от друга. Кроме того, предполагается что порядок каждой пары товаров $ i,j $ является независимым от порядков других пар. Отсюда, функцию $ p(>_U | \theta) $ можно 
переписать как:
\begin{equation}
	\prod_{u \in U} p(>_u | \theta) = 	\prod_{(u,i,j) \in U \times I \times I} p(i >_u j | \theta )^{\sigma(u,i,j) \in D_S} (1 - p(i >_u j | \theta ))^{\sigma(u,i,j) \notin D_S}
\end{equation}.
Причем
\begin{equation}
	\sigma(b) = \begin{cases}
		1 & if \ b == true \\
		0 & otherwise
	\end{cases}
\end{equation}
Однако, используя тот факт, что схема попарного ранжирования всеобща и антисимметрична, можно упростить данную формулу до:
\begin{equation}
	prod_{u \in U} p(>_u | \theta) = \prod_{(u,i,j) \in D_S} p(i >_u j | \theta)
\end{equation}

Введем жесткое исполнение свойств всеобщности и антисимметричности. Для этого введем индивидуальную вероятность того, что пользователь $ u $ предпочтет товар $ i $ товару $ j $ как $p(i >_u j) = \sigma(\hat{x}_{uij}(\theta))$, где $\sigma(x) = \frac{1}{1+e^{-x}}$. Здесь $ \hat{x}_{uij}(\theta) $ - функция от вектора $\theta$ которая и описывает отношения пользователя $u$ и товаров $ i,j $. Таким образом, мы делегируем моделирование отношений внутреннему классу модели(здесь использована факторизация матриц, описанная в параграфе про ALS).  
Для того чтобы закончить моделирование по Байесу, введем понятие "Общей плотности" $ p(\theta) $, которая является нормальным распределением с математическим ожиданием = 0 и матрицей ковариации $ \sum_{\theta} $: $p(\theta) = N(0,\sum_{\theta})$.
Сокращая количество неизвестных переменных, представим $ \sum_{\theta} $ как $ \lambda_{\theta} I $. Тогда сформулируем Байесовский критерий оптимизации BPR-Opt:
\begin{equation}
	\begin{split}
		BPR-Opt = ln(p(\theta) |  >_u) = \\
		ln(p(>_u | \theta)p(\theta)	= \\
		ln \prod_{(u,i,j) \in D_S} \sigma_{\hat{x_{uij}}}p(\theta) = \\ 
		\sum_{(u,i,j \in D_S)}ln \ \sigma(\hat{x}_{uij}) + ln \  p(\theta) = \\
		\sum_{(u,i,j \in D_S)}ln \ \sigma(\hat{x}_{uij}) - \lambda_{\theta} \parallel \theta \parallel ^ 2
	\end{split}
\end{equation}

Рассмотрим сам алгоритм обучения LearnBPR. Это специальный алгоритм, основанный на стохастическом градиентом спуске и динамической выборке триплетов для тренировки.

Найдем градиент BPR-Opt.
\begin{multline}
	\frac{\partial BPR-Opt}{\partial \theta} = \sum_{(u,i,j \in D_S)} \frac{\partial}{\partial \theta} ln \ \sigma(\hat{x}_{uij}) - \lambda_{\theta} \frac{\partial}{\partial \theta} \parallel \theta \parallel ^ 2 \propto \\
	 \sum_{(u,i,j \in D_S)} \frac{- e^{-\hat{x}_{uij}}}{1 + e^{-\hat{x}_{uij}}} \frac{\partial}{\partial \theta} \hat{x}_{uij} - \lambda_{\theta} \theta
\end{multline}

Соответственно, можно записать и общий алгоритм LearnBPR.\\
\begin{algorithm}[H]\label{bpr:1}
	\caption{Предусловленный метод решения системы $Aw = b$ методом сопряженных градиентов.}
	\KwIn{$D_S, \theta$}
	\KwOut{$\theta$}
	initialize $\theta$ \\
	\While{not convergence}{
	take $(u,i,j)$ из $D_S$ \\
		$\theta \leftarrow \theta + \alpha (\frac{- e^{-\hat{x}_{uij}}}{1 + e^{-\hat{x}_{uij}}} \frac{\partial}{\partial \theta} \hat{x}_{uij} - \lambda_{\theta} \theta) $
	}
	return $\theta$
\end{algorithm}

Особо следует отметить выбор данных для тренировки. Если выбирать данные триплетов принадлежащих к одному пользователю или товару, то сходимость даже стохастического градиентного спуска будет медленной, так как для пары $(u,i)$ существует много $j$, для которых выполняется что $(u,i,j) \in D_S$. Соответственно статья \cite{BPR:1205} предлагает выбирать триплеты случайно и равномерно. С таким подходом шанс выбрать одинаковые пары пользователь-товар достаточно мал, и поэтому алгоритм сходится значительно быстрее.

\subsection{AE}
Модель AE(AutoEncoder) принадлежит к классу collaborative filtering, а также является представителем semi-supervised learning. \\

Рассмотрим подробнее, что такое автоенкодер. 

Как известно, автоенкодер представляет собой нейронную сеть состоящую из двух частей - encoder и decoder. Эти части соответственно выполняют преобразования  $encode(x) : R^n \rightarrow R^d$ и $decode(x) : R^d \rightarrow R^n$, где $n$ - исходная размерность данных, а $d$ - целевая размерность. Цель этих преобразований получить представление данных исходной размерности $n$ в размерности $d$ такую, чтобы минимизировать отклонение исходных данных от полученных: $x - decode(encode(x)) -> min$.

В данной модели и encoder и decoder - feed-forward сети с полносвязными слоями $I = f(W*x + b)$, где $f$ - некоторая нелинейная активационная функция, причем архитектура decoder такая же, как и архитектура encoder. 

Рассмотрим принцип работы систем. Forward pass - на вход подается вектор рейтингов пользователя $x \in R^M$, где $M$ - количество продуктов. На выходе мы получаем вектор $x \in R^M$, но с одним значительным отличием - на входе вектор был разреженным, на выходе все значения пользователя заполнены.

Особо стоит отметить процесс выбора функций активации и loss-функции. Для функции активации, классическим решением было бы использование RELU(Rectified Linear Unit). Однако, вследствие характера обрабатываемых данных(implicit feedback пользователей), нежелательна потеря отрицательных значений после активации, что делает нерациональным его использование. Поэтому в качестве функции используется ELU(Exponential Linear Unit). В дальнейшем будет произведен эксперимент с использованием SELU(Scaled Exponential Linear Unit).\\

Приведем формулы всех трех функций активации.
\begin{equation}
	ELU(x) = \begin{cases}
		x & x > 0 \\
		exp(x) - 1 & x \leq 0
	\end{cases}
\end{equation}
\begin{equation}
	RELU(x) = max(0,x)
\end{equation}
\begin{equation}
	SELU(x) = scale * (max(0,x) + min(0, \alpha * (exp(x) - 1)))
\end{equation}

Применение таких функций дало следующие результаты:

\begin{tabular}{| l |l| l| l| l|}
	\hline
	Модель & DCG@30 & HappyUsersRatio@5 & IOU@30 &  NAP@30 \\
	\hline
	ELU & 0.02464 & 0.11504 & 0.02029 & 0.00535 \\
	\hline
	SELU & 0.02949 & 0.10442 & 0.01994 &  0.0861 \\
	\hline
	RELU & 0.07552 & 0.25841 & 0.04696 &  0.02894 \\
	\hline
\end{tabular}\\
\\

В подобных задачах \cite{AE:a1} часто используют masked mse (loss оценивается только по не нулевым позициям входного вектора, позволяя сети сколько угодно сильно "ошибаться" по тем позциям, где стояли нули.) в качестве loss-функции.
\begin{equation}
	MMSE = \frac{m_i * (r_i - y_i) ^ 2}
	{\sum_{i=0}^{i=n} m_i}
\end{equation}  
Однако в процессе экспериментов выяснилось, что результаты нейронной сети с такой конфигурацией значительно хуже. Тогда было принято решение использовать обычный MSE, имеющий формулу:
\begin{equation}
	MSE = \frac{1}{n} \sum_i=1^n(r_i-y_i)
\end{equation}
MSE не может занулить все наши рекомендации просто потому, то автоэнкодер не может дать 100\% точность после разжатия данных.

Модель реализована с использованием пакета TensorFlow=2.4.2. Использование программного пакета CUDA позволяет производить обучение на с использованием графических ускорителей. Обучение модели происходит на протяжении 500 эпох, с использованием batch\_size = 256.Время обучение даже с использованием графического ускорителя достаточно велико - около 30 минут. 

 

%TODO Check
\begin{figure}[H]
	\begin{tikzpicture}[main/.style = {draw, rectangle},node distance= 1cm,align=left]
		\node[main] (1) {Input(, N)}; 
		\node[main] (2) [right=1cm of 1] {Dense(256)}; 
		\node[main] (3) [right=1cm of 2] {ELU};
		\node[main] (4) [right=1cm of 3] {Dense(256)}; 
		\node[main] (5) [right=1cm of 4] {ELU};
		\draw[->] (1) -- (2);
		\draw[->] (2) -- (3);
		\draw[->] (3) -- (4);
		\draw[->] (4) -- (5);
	\end{tikzpicture}
	\caption{Архитектура модели AE}\label{stud:fig:2}
\end{figure}


\subsection{IP}
Модель IP является представителем item-based подхода. \\

Как уже говорилось, создается представление данных IP, в котором каждый товар представляется как вектор размерности $n$, где $n$ - общее количество бинаризованных фильтров. Т.е существует метрическое пространство $\mathbb{R}^n$ c набором векторов $x \in \mathbb{R}^n$. Задача - для  $\forall q \in \mathbb{R}^n$ найти $N$ ближайших точек к $q$.

Построенные данные используются для обучения модели, основанной на алгоритме нахождения ближайших соседей, который реализован в пакете Sklearn как алгоритм Sklearn.NearestNeighbours. Рассмотрим его подробнее.

%Здесь должно быть описание алгоритма KDtree

Необходимо выбрать метрику, которая будет использоваться в нашем алгоритме. Рассмотрим несколько возможных вариантов метрик:
\begin{enumerate}
	\item Косинусная метрика. Данная метрика является достаточно универсальной и подходит практически везде.
	\item Жаккардова метрика. Данная метрика хороша для бинаризованных классов.
	\item Метрика Dice
	\item Евклидова метрика
	\item Манхэттенская метрика
	\item Метрика Чебышева
	\item Метрика Минковского
\end{enumerate} 

\begin{tabular}{| l |l| l| l| l|}
	\hline
	Метрика & DCG@30 & HappyUsersRatio@5 & IOU@30 &  NAP@30 \\
	\hline
	Cosine & 0.03754 & 0.12851 & 0.02505 & 0.01080 \\
	\hline
	Jaccard &  0.03101 &0.11245 & 0.02155 & 0.00779\\
	\hline
	Dice & 0.03101 & 0.11245 & 0.02155 & 0.00779 \\
	\hline
	eucledian & 0.03459 & 0.11245 & 0.02302 & 0.00972 \\
	\hline
	manhattan & 0.03613 & 0.12249 & 0.02377 & 0.01029 \\
	\hline
	chebyshev & 0.03200 & 0.10843 & 0.02113 & 0.00897 \\
	\hline
	minkowski & 0.03459 & 0.11245 & 0.02302 & 0.00972 \\
	\hline

\end{tabular}\\
Как можно заметить, наилучшие показатели модель получила при работе с косинусной метрикой, которая, по совместительству, является и наиболее универсальной. Именно поэтому данная метрика и будет использоваться в дальнейшем.
	
Построенные в представлении данных IP профили товаров используются как обучающий dataset для модели sklearn.NearestNeighbours, имеющий в основе алгоритм KD-Tree. Данная модель позволяет как рекомендовать товары, похожие на данный, так и рекомендовать товары на основе истории пользователя.  
В случае рекомендаций товаров на основе истории взаимодействий пользователя, применяется нижеописанный алгоритм. Здесь $N$ - количество необходимых рекомендаций, $u$ - пользователь, для которого даются рекомендации, $k$ - максимальное число похожих на данный товар товаров, $D_u$ - набор товаров, с которыми взаимодействовал пользователь.   \\
\begin{algorithm}[H]\label{IP:1}
	\caption{Алгоритм генерации рекомендаций с помощью IP}
	\KwIn{$N, D_u, z$}
	\KwOut{Набор товаров}
	result = \{\} \\
	i = 0 \\
	sort $D_u$ by popularity\\
	\While{len(result) < N}{
		result $\leftarrow$ result $\wedge$ kNN($D_u[i]$)
	}
	return result
\end{algorithm}
В случае, если алгоритм не позволяет найти необходимое количество товаров($len(result) < N$), что происходит, например, в ситуации когда пользователь малоактивен и/или начал пользоваться сайтом недавно, результат дополняется результатами модели TopN до необходимого количества рекомендаций. 
Правило брать не более чем k похожих на текущий товара выведено экспериментально, в противном случае рекомендация получается маловариативной, и как соответствие, зачастую худшей по качеству. Число k=3 выведено экспериментальным путем. 
\subsection{UIP}
Аналогично, построенные в представлении данных UIP профили пользователей используются как обучающий dataset для модели sklearn.NearestNeighbours, имеющий в основе алгоритм KD-Tree. Данная модель позволяет находить пользователей, похожих на данного, и, соответственно, рекомендовать пользователю товары, являющиеся популярными у похожих пользователей.
Применяется следующий алгоритм:

\begin{algorithm}[H]\label{UIP:1}
	\caption{Алгоритм генерации рекомендаций с помощью UIP}
	\KwIn{$N, D_u, z$}
	\KwOut{Набор товаров}
	result = \{\} \\
	i = 0 \\
	sort $D_u$ by popularity\\
	\While{len(result) < N}{
		result $\leftarrow$ result $\wedge$ kNN($D_u[i]$)
	}
	return result
\end{algorithm}

Аналогично, правило брать не более чем 5 товаров у похожего пользователя выведено экспериментально.
\subsection{DRN}

Данная модель примечательна тем, что она является гибридной, совмещая в себе подходы collaborative filtering и content-based. Также, она примечательна и своей конструкцией - это сиамская нейронная сеть, имеющая структуру, приведенную ниже. Задача этой сети - обучиться отличать вещи которые могут понравиться пользователю. Необычен и процесс обучения - на вход данной модели подаются тройки вида (профиль пользователя, профиль понравившейся ему вещи, профиль не понравившейся ему вещи).

Данная модель использует две подмодели - для создания embedding товаров (Dense Layer размерности 64, ReLU, Dense Layer размерности 32, ReLU) и embedding пользователей (Dense Layer размерности 32, ReLU). Оба embedding передаются в ScoreLayer, где определяется близость embedding пользователя к embedding не понравившейся ему вещи и близость embedding пользователя к embedding понравившейся ему вещи.  Финальный слой -TripletLossLayer - определяет разницу score.

Стоит отметить, что слои TripletLossLayer и ScoreLayer реализованы специально для этой модели.

Из-за сложности и специализированных слоев данная модель имеет низкую скорость обучения, и не показывает высоких результатов. Вследствие этого, будет производится исследование возможности доработки данной модели.

\subsection{Сравнительный анализ моделей}
Для сравнительного анализа моделей была рассчитаны метрики для всех моделей на тестовом датасете, содержащем данные за 2 недели, и сведены в единую таблицу.\\
\begin{tabular}{| l |l| l| l| l|}
	\hline
	Модель & DCG@30 & HappyUsersRatio@5 & IOU@30 &  NAP@30 \\
	\hline
	Top30 & 0.02464 & 0.11504 & 0.02029 & 0.00535 \\
	\hline
	ALS & 0.02949 & 0.10442 & 0.01994 &  0.0861 \\
	\hline
	AE & 0.07552 & 0.25841 & 0.04696 &  0.02894 \\
	\hline
	IP & 0.03612 & 0.12249 & 0.02375 &  0.01038 \\
	\hline
	UIP & 0.5002 & 0.26707 & 0.0207 &  0.02035 \\
	\hline
	DRN & 0.00861 & 0.03363 & 0.0027 & 0.00401 \\
	\hline
	Ансамбль & 0.8889 & 0.26707 & 0.04164 &  0.02504 \\
	\hline
\end{tabular}\\ \\
Основополагающей метрикой здесь является метрика HappyUsersRatio.
Как мы видим, наилучший результат показала модель UIP.

%=======================

\section{Создание ансамбля моделей}
Для улучшения результатов, был создан автоматический ансамбль, который выбирает лучшую collaborative-filtering модель и лучшую content-based - модель(в данном случае единственную - IP). Рекомендации от обоих моделей формируются в шахматном порядке, повторы исключаются, а товары, которые предсказали обе модели идут в начало. Вследствие того, что в ансамбле присутствуют модели, сходные по характеристикам, а в результате обучения метрики немного меняются в зависимости от данных, этот подход позволяет потенциально всегда выбирать наилучшие модели для заданных магазинов.
Сравним метрики, полученные таким способом, с уже имеющимися:\\
\begin{tabular}{| l |l| l| l| l|}
	\hline
	Модель & DCG@30 & HappyUsersRatio@5 & IOU@30 &  NAP@30 \\
	\hline
	Top30 & 0.02464 & 0.11504 & 0.02029 & 0.00535 \\
	\hline
	ALS & 0.02949 & 0.10442 & 0.01994 &  0.0861 \\
	\hline
	AE & 0.07552 & 0.25841 & 0.04696 &  0.02894 \\
	\hline
	IP & 0.03612 & 0.12249 & 0.02375 &  0.01038 \\
	\hline
	UIP & 0.5002 & 0.26707 & 0.0207 &  0.02035 \\
	\hline
	DRN & 0.00861 & 0.03363 & 0.0027 & 0.00401 \\
	\hline
	Ансамбль & 0.8889 & 0.26707 & 0.04164 &  0.02504 \\
	\hline
\end{tabular}\\
\\
Следует отметить, что модели AE и UIP имеет одни из лучших метрик, а итоговый ансамбль опережает даже их, что говорит о целесообразности данного подхода.

%=======================

%=======================
\newpage
\addcontentsline{toc}{section}{Заключение}
\section*{Заключение}

Как итог, на данный момент создана универсальная рекомендательная система с адаптивным ансамблем моделей, способная к полностью автоматическому переформированию представлений данных, пересозданию и переобучению моделей, способная работать для любого интернет-магазина при условии предоставления им стандартизированной выгрузки данных. На данный момент производится А/B тестирование на серверах интернет-магазинов для определения действительной эффективности системы. \\
Кроме того, текущий результат работы был опубликован на конференции МКО-2022 в виде тезисов и видеопрезентации доклада. [Приложение 2], а также на конференции СИТО-2022 в виде тезисов и презентации доклада.

Существует несколько приложений по доработке системы, в частности:
\begin{enumerate}
	\item Добавить возможность разделения часто и редко покупаемых товаров.
\end{enumerate}



%=======================
\newpage

\addcontentsline{toc}{section}{Литература}
\renewcommand{\refname}{\centering \textbf{Литература}}

% БИБЛИОГРАФИЯ

\begin{thebibliography}{0}
\bibitem{stud:b0}
Рекомендации по оформлению
и представлению курсовых
и выпускных квалификационных работ
студентов института математики,
механики и компьютерных наук.~--
Ростов н/Д, 2020.

\bibitem{stud:b1}
Жуков М.\,Ю., Ширяева Е.\,В.
\LaTeXe: искусство набора и вёрстки текстов с~формулами.~-- Ростов н/Д : Изд-во ЮФУ, 2009.

\bibitem{stud:kimfalk1}{
Ким Фальк
Рекомендательные системы на практике.

}
\bibitem{ALS:a1}{
	Gábor Takács, Domonkos Tikk,
	Alternating least squares for personalized ranking,
	DOI: 10.1145/2365952.2365972 
}

\bibitem{ALS:a2}{
	Github reporistory of "implicit" library,
	https://github.com/benfred/implicit,
	обр. 2021-12-28,
}

\bibitem{ALS:CFIFD}{
	Yifan Hu, Yehuda Koren, Chris Volinsky,
	Collaborative Filtering for Implicit Feedback Datasets,
	DOI: TODO
}

\bibitem{ALS:rwe}{
	Yifan Hu, Yehuda Koren, Chris Volinsky,
	Collaborative Filtering for Implicit Feedback Datasets,
	DOI: TODO
}

\bibitem{AE:a1}{
	Oleksii Kuchaiev, Boris Ginsburg,
	Training Deep AutoEncoders for Collaborative Filtering,
	https://arxiv.org/pdf/1708.01715.pdf 
}

\bibitem{DRN:a1}{
	Ali Elkahky, Yang Song, Xiaodong He,
	A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems,
	https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/frp1159-songA.pdf 
}

\bibitem{INTRO:a1}
{
	https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers
}

\end{thebibliography}



\end{document}
% ----------------------------------------------------------------


\lstset{ %
language=Python,                 % выбор языка для подсветки (здесь это С++)
basicstyle=\small\sffamily, % размер и начертание шрифта для подсветки кода
numbers=left,               % где поставить нумерацию строк (слева\справа)
numberstyle=\tiny,           % размер шрифта для номеров строк
stepnumber=1,                   % размер шага между двумя номерами строк
numbersep=5pt,                % как далеко отстоят номера строк от подсвечиваемого кода
backgroundcolor=\color{white}, % цвет фона подсветки - используем \usepackage{color}
showspaces=false,            % показывать или нет пробелы специальными отступами
showstringspaces=false,      % показывать или нет пробелы в строках
showtabs=false,             % показывать или нет табуляцию в строках
frame=single,              % рисовать рамку вокруг кода
tabsize=2,                 % размер табуляции по умолчанию равен 2 пробелам
captionpos=t,              % позиция заголовка вверху [t] или внизу [b]
breaklines=true,           % автоматически переносить строки (да\нет)
breakatwhitespace=false, % переносить строки только если есть пробел
escapeinside={\%*}{*)}   % если нужно добавить комментарии в коде
extendedchars=true,
commentstyle=\color{mygreen},    % comment style
stringstyle=\bf,
commentstyle=\ttfamily\itshape,
keepspaces=true % пробелы между русскими буквами
aboveskip=3mm,
belowskip=3mm

}


\renewcommand\NAT@bibsetnum[1]{\settowidth\labelwidth{\@biblabel{#1}}%
   \setlength{\leftmargin}{\bibindent}\addtolength{\leftmargin}{\dimexpr\labelwidth+\labelsep\relax}%
   \setlength{\itemindent}{-\bibindent+\fivecharsapprox}%
   \setlength{\listparindent}{\itemindent}
\setlength{\itemsep}{\bibsep}\setlength{\parsep}{\z@}%
   \ifNAT@openbib
     \addtolength{\leftmargin}{\bibindent}%
     \setlength{\itemindent}{-\bibindent}%
     \setlength{\listparindent}{\itemindent}%
     \setlength{\parsep}{0pt}%
   \fi
}
\renewcommand{\thesection}{\arabic{section}.}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}.}
